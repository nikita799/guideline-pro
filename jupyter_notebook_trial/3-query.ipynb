{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b23e58e-79c3-4c30-8bf4-d2e507269a02",
   "metadata": {},
   "source": [
    "Here I will try out different cloud solutions to query and see how they perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827a4e1b-cd91-4e28-9709-e974b2d26292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸ Deleted existing collection: 'Guideline'\n",
      "âœ… Created clean collection: 'Guideline'\n",
      "ðŸ“¦ Loaded 26 objects from JSONL\n",
      "ðŸš€ Successfully imported 26 objects into 'Guideline'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import weaviate\n",
    "from weaviate.auth import Auth\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "JSONL_PATH = \"data/t2d_guideline_ee/30_chunks/2-tuubi-diabeedi-diagnostika-ravi.jsonl\"\n",
    "COLLECTION_NAME = \"Guideline\"\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "if not WEAVIATE_URL:\n",
    "    raise ValueError(\"Missing WEAVIATE_URL in environment.\")\n",
    "if not WEAVIATE_API_KEY:\n",
    "    raise ValueError(\"Missing WEAVIATE_API_KEY in environment.\")\n",
    "\n",
    "\n",
    "# Code below adds the JSONL objects to Weaviate collection.\n",
    "def load_jsonl_objects(path: str) -> list[dict]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    objects: list[dict] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line_no, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Invalid JSON on line {line_no}: {e}\") from e\n",
    "\n",
    "            # Support both:\n",
    "            # 1) {\"properties\": {...}}  and 2) {...flat props...}\n",
    "            props = data.get(\"properties\", data)\n",
    "            if not isinstance(props, dict):\n",
    "                raise ValueError(f\"Expected dict properties on line {line_no}, got {type(props)}\")\n",
    "\n",
    "            objects.append(props)\n",
    "\n",
    "    return objects\n",
    "\n",
    "\n",
    "with weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    ") as client:\n",
    "\n",
    "    # --- PART 1: CREATE COLLECTION ONLY IF MISSING ---\n",
    "    if not client.collections.exists(COLLECTION_NAME):\n",
    "        client.collections.create(\n",
    "            name=COLLECTION_NAME,\n",
    "            vector_config=Configure.Vectors.text2vec_weaviate(\n",
    "                name=\"default\",\n",
    "                source_properties=[\"search_text\"],\n",
    "                vectorize_collection_name=False,\n",
    "            ),\n",
    "            properties=[\n",
    "                Property(name=\"chunk_id\", data_type=DataType.INT),\n",
    "                Property(name=\"search_text\", data_type=DataType.TEXT),\n",
    "                Property(name=\"text\", data_type=DataType.TEXT),\n",
    "                Property(name=\"breadcrumbs\", data_type=DataType.TEXT),\n",
    "                Property(name=\"source\", data_type=DataType.TEXT),\n",
    "                Property(name=\"year\", data_type=DataType.INT),\n",
    "                Property(name=\"language\", data_type=DataType.TEXT),\n",
    "                Property(name=\"version_id\", data_type=DataType.TEXT),\n",
    "            ],\n",
    "        )\n",
    "        print(f\"âœ… Created collection: '{COLLECTION_NAME}'\")\n",
    "    else:\n",
    "        print(f\"â„¹ï¸ Collection already exists: '{COLLECTION_NAME}' (will append new objects)\")\n",
    "\n",
    "    # --- PART 2: IMPORT OBJECTS (APPEND) ---\n",
    "    guideline_collection = client.collections.use(COLLECTION_NAME)\n",
    "\n",
    "    objects_to_add = load_jsonl_objects(JSONL_PATH)\n",
    "    print(f\"ðŸ“¦ Loaded {len(objects_to_add)} objects from JSONL\")\n",
    "\n",
    "    # Batch import (append)\n",
    "    with guideline_collection.batch.fixed_size(batch_size=200) as batch:\n",
    "        for props in objects_to_add:\n",
    "            batch.add_object(properties=props)\n",
    "\n",
    "    # --- PART 3: CHECK IMPORT STATUS ---\n",
    "    failed = guideline_collection.batch.failed_objects\n",
    "    if failed:\n",
    "        print(f\"âŒ Failed to import {len(failed)} objects.\")\n",
    "        print(\"First failure:\")\n",
    "        print(failed[0])\n",
    "    else:\n",
    "        total = guideline_collection.aggregate.over_all(total_count=True).total_count\n",
    "        print(f\"ðŸš€ Import complete. Collection '{COLLECTION_NAME}' now has {total} objects total.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc3729a4-980e-4bc1-bc33-d8cefd584420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "A) near_text (semantic)\n",
      "==========================================================================================\n",
      "\n",
      "[1] uuid=533a0d75-6996-4542-ae3b-a7c9243418a6\n",
      "  chunk_id: 7\n",
      "  search_text: Ravijuhendi soovituste loetelu > Farmakoteraapia alustamine 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil, kel puudub SVH lisarisk\n",
      "7. **2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil, kes vajab farmakoteraapiat ja kellel ei esine pÃ¼siva proteinuuriagaÂ² kroonilist neeruhaigust vÃµi dokumenteeritud sÃ¼dame vasaku vatsakese langenud vÃ¤ljutusfraktsioonigaÂ³ sÃ¼damepuudulikkust, alustage ravi metformiiniga.**\n",
      "Tugev positiivne soovitus, vÃ¤ga madal tÃµendatuse aste\n",
      "8. **2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil alustage metformiinravi annuses vÃ¤hemalt 500 mg kaks korda pÃ¤evas. Vajaduse korral suurendage annust mitme nÃ¤dala jooksul jÃ¤rk-jÃ¤rgult, et vÃ¤hendada gastrointestinaalsete kÃµrvaltoimete riski.**\n",
      "Praktiline soovitus\n",
      "9. **2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil, kellel on metformiin vastunÃ¤idustatud vÃµi kes seda ei talu, kaaluge farmakoteraapia alustamist sulfonÃ¼Ã¼luurea preparaadi, DPP4 inhibiitori, SGLT2 inhibiitoriâ´ vÃµi pioglitasooniga.**\n",
      "NÃµrk positiivne soovitus, vÃ¤ga madal tÃµendatuse aste\n",
      "  source: 2. tÃ¼Ã¼bi diabeedi diagnostika ja ravi\n",
      "  year: 2021\n",
      "  language: et\n",
      "  search_text (snippet): Ravijuhendi soovituste loetelu > Farmakoteraapia alustamine 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil, kel puudub SVH lisarisk 7. **2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil, kes vajab farmakoteraapiat ja kellel ei esine pÃ¼siva proteinuuriagaÂ² kroonilist neeruhaâ€¦\n",
      "\n",
      "[2] uuid=fee6c2ad-fc69-4ef0-905b-ef0f16627c19\n",
      "  chunk_id: 17\n",
      "  search_text: Ravijuhendi soovitused koos tÃµenduse ja arutelu lÃ¼hikokkuvÃµttega > Prediabeedi kÃ¤sitlus\n",
      "Prediabeet on seisund, mille puhul ei ole vere glÃ¼koosisisaldus nii suur, et diagnoosida diabeeti, kuid on liiga suur, et pidada normaalseks (2). Prediabeediks peetakse paastuglÃ¼koosi hÃ¤iret (IFG) ja/vÃµi glÃ¼koosi taluvuse hÃ¤iret (IGT) ja/vÃµi HbA1c-d vahemikus 6,0%â€“6,4% (42â€“47 mmol/mol) (9, 10). Rahvusvahelise Diabeedi FÃ¶deratsiooni (IDF) andmeil mÃµjutas IFG maailmas 2019. aastal 374 miljonit tÃ¤iskasvanut vanuses 20â€“79 eluaastat, mis teeb IFG levimuseks selles vanuserÃ¼hmas 7,5% (5). Xu et al. (2020) sÃ¼stemaatiline Ã¼levaade ja metaanalÃ¼Ã¼s nÃ¤itas, et prediabeediga inimestel oli vÃµrreldes normoglÃ¼keemilistega peaaegu kuus korda suurem risk haigestuda 2. tÃ¼Ã¼pi diabeeti (RR 5,88; 95% CI 5,02; 6,89) (12).  \n",
      "Eesti ravijuhend â€žÃœlekaalulise vÃµi rasvunud patsiendi kÃ¤sitlus esmatasandilâ€œ (2019) Ã¼tleb, et eluviisi nÃµustamine on eluviisi, sh toitumis- ja liikumisharjumuste muutmine, milleks kasutatakse eri sekkumisi (13). 2. tÃ¼Ã¼pi diabeedi ennetamiseks ja/vÃµi edasilÃ¼kkamiseks vÃµib kasutada nii eluviisisekkumisi kui ka farmakoteraapiat. Mitu suurt juhuslikustatud kontrolliga katset (RCT) (sh The Diabetes Prevention Program, The Finnish Diabetes Prevention Study ja The DaQing Diabetes Prevention Study) on uurinud eluviisisekkumiste mÃµju 2. tÃ¼Ã¼pi diabeedi ennetamisele (14â€“16). Farmakoteraapia kasutamisest 2. tÃ¼Ã¼pi diabeedi ennetamisel on kÃµige rohkem tÃµendust metformiini kohta (17).  \n",
      "**Soovitused**\n",
      "1. Prediabeediga patsient suunake eluviisisekkumise intensiivprogrammi.\n",
      "Tugev positiivne soovitus, mÃµÃµdukas tÃµendatuse aste\n",
      "2. Prediabeediga patsiendil Ã¤rge metformiinravi pigem kasutage.\n",
      "NÃµrk negatiivne soovitus, mÃµÃµdukas tÃµendatuse aste  \n",
      "TÃµendusmaterjal pÃ¤rines viiest sÃ¼stemaatilisest Ã¼levaatest ja metaanalÃ¼Ã¼sist (17â€“21) ning kahest RCT-st (22, 23). TÃµendusmaterjalina arvesse vÃµetud mÃµÃµduka tÃµendatuse astmega tÃµendus nÃ¤itas, et nii eluviisisekkumine kui ka farmakoteraapia vÃ¤hendasid prediabeediga uuritavatel vÃµrreldes kontrollrÃ¼hmaga (standardravi vÃµi platseebo) 2. tÃ¼Ã¼pi diabeeti haigestumist (19â€“21). Farmakoloogilise ravi mÃµju lÃµppes pÃ¤rast ravimi manustamist. Eluviisisekkumise mÃµju oli pÃ¤rast sekkumise lÃµppu pÃ¼sivam (20). Suremus ei erinenud, kui vÃµrreldi metformiini toitumisalase sekkumise ja fÃ¼Ã¼silise aktiivsuse kombinatsiooniga (17). Metformiinravi ei olnud prediabeediga uuritavatel vÃµrreldes intensiivse eluviisisekkumisega tÃµhusam 2. tÃ¼Ã¼pi diabeedi ennetamisel ja paastuglÃ¼koosi ning HbA1c langetamisel (mÃµÃµdukas tÃµendatus) (17).  \n",
      "TÃ¶Ã¶rÃ¼hm vÃµttis soovituse sÃµnastamisel arvesse, et inimesed, kes osalevad eluviisisekkumise programmides, on tÃµenÃ¤oliselt keskmisest motiveeritumad. Enamik prediabeediga patsiente on nÃµus oma eluviisis midagi muutma. Intensiivse eluviisisekkumise potentsiaalsed soovimatud mÃµjud on vaimne pinge ja olemasoleva toitumishÃ¤ire vÃµimendumine (kahtlusel tuleb selle suhtes sÃµeluda).  \n",
      "Farmakoteraapias kasutatakse valdavalt metformiini. Metformiini vÃ¤ga sage kÃµrvaltoime on seedetrakti Ã¤rritus, nagu iiveldus, oksendamine, kÃµhulahtisus, kÃµhuvalu ja sÃ¶Ã¶giisu kaotus. Need kÃµrvaltoimed esinevad kÃµige sagedamini ravi alustamisel ja enamikul juhtudel lahenevad spontaanselt. Ravi metformiiniga on uuritud peamiselt 2. tÃ¼Ã¼pi diabeedi ennetamisel. MÃµju suremusele ja SV tulemitele enamasti hinnatud ei ole. Kuigi metformiinravi vÃ¤hendab veresuhkru taset ja esmashaigestumist 2. tÃ¼Ã¼pi diabeeti, puudub tÃµestatud mÃµju teistele kliiniliselt olulistele tulemusnÃ¤itajatele, sh sÃ¼dame-veresoonkonnale.  \n",
      "Vaata lÃ¤hemalt kliinilise kÃ¼simuse number 1 TÃµKo tabelit ja SoKo tabelit.  \n",
      "---\n",
      "  source: 2. tÃ¼Ã¼bi diabeedi diagnostika ja ravi\n",
      "  year: 2021\n",
      "  language: et\n",
      "  search_text (snippet): Ravijuhendi soovitused koos tÃµenduse ja arutelu lÃ¼hikokkuvÃµttega > Prediabeedi kÃ¤sitlus Prediabeet on seisund, mille puhul ei ole vere glÃ¼koosisisaldus nii suur, et diagnoosida diabeeti, kuid on liiga suur, et pidada normaalseks (2). Prediabeediks peetakse paaâ€¦\n",
      "\n",
      "[3] uuid=3b1f6d03-9187-4e59-9ad3-91dd119437b1\n",
      "  chunk_id: 20\n",
      "  search_text: Lisad > Lisa 1. 2. tÃ¼Ã¼pi diabeedi ravi algoritm > Ravi eesmÃ¤rkvÃ¤Ã¤rtused (Lisa 1 plokk)\n",
      "1) 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil seadke HbA1cÂ¹ eesmÃ¤rkvÃ¤Ã¤rtuseks < 7,0% (53 mmol/mol)\n",
      "2) Eluviisiprogrammis osaleval vÃµi metformiini monoteraapial oleval patsiendil, kellel pole diabeedi kaugtÃ¼sistusi ega varem diagnoositud SVH, kaaluge eesmÃ¤rki < 6,5% (48 mmol/mol)\n",
      "3) Kauakestnud diabeediga, vÃ¤ljendunud hilistÃ¼sistustega, raskete kaasuvate haigustega vÃµi eelnevalt raskeid hÃ¼poglÃ¼keemiaid lÃ¤bi teinud patsiendil, kaaluge vÃ¤hem rangeid eesmÃ¤rkvÃ¤Ã¤rtuseid < 8,0% (64 mmol/mol)  \n",
      "- eGFR 45â€“60 ml/min/1,73m2\n",
      "- SGLT2i alustatud ravi vÃµib jÃ¤tkata, KNH vÃµi sÃ¼damepuudulikkuse puudumisel ravi mitte alustada\n",
      "- Metformiin maksimaalselt 2000 mg\n",
      "- eGFR 30â€“45 ml/min/1,73m2\n",
      "- SGLT2i KNH vÃµi sÃ¼damepuudulikkuse puudumisel ravi mitte alustada.\n",
      "- Metformiin maksimaalselt 1000 mg. DPP-4i annust vÃ¤hendada (va linagliptiin)\n",
      "- TÃ¤psem info LISAs 3  \n",
      "Aterosklerootiline kardiovaskulaarhaigus:\n",
      "1. SÃ¼dame isheemiatÃµbi: stenokardia(I20.0), mÃ¼okardiinfarkt (I21-I22), koronaare revaskulariseerivad protseduurid (Z95.5 ja Z95.1), koronaararterite stenoos Ã¼le 50% (I25 koos laienditega).\n",
      "2. Tserebrovaskulaarsed haigused: intratserebraalne hemorraagia (I61 koos laiendiga); peaajuinfarkt (I63 koos laiendiga); tÃ¤psustamata kas hemorraagia vÃµi infarktitekkene insult e rabandus (I64); pretserebraal-arterite peaajuinfarktita oklusioon e sulgus ja stenoos e ahenemus (I65 koos laiendiga); peaajuarterite peaajuinfarktita oklusioon ja stenoos (I66 koos laiendiga); Insuldi (tÃ¤psustamata kas hemorraagia vÃµi infarkt) jÃ¤Ã¤knÃ¤hud (I69.4).\n",
      "3. Aordi ja perifeersete arterite aterosklerootiline kahjustus (I70 ja I71 koos laiendiga)  \n",
      "---\n",
      "  source: 2. tÃ¼Ã¼bi diabeedi diagnostika ja ravi\n",
      "  year: 2021\n",
      "  language: et\n",
      "  search_text (snippet): Lisad > Lisa 1. 2. tÃ¼Ã¼pi diabeedi ravi algoritm > Ravi eesmÃ¤rkvÃ¤Ã¤rtused (Lisa 1 plokk) 1) 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendil seadke HbA1cÂ¹ eesmÃ¤rkvÃ¤Ã¤rtuseks < 7,0% (53 mmol/mol) 2) Eluviisiprogrammis osaleval vÃµi metformiini monoteraapial oleval patsiendâ€¦\n",
      "\n",
      "[4] uuid=fd029746-1933-4e31-9a2e-e90a559461ae\n",
      "  chunk_id: 19\n",
      "  search_text: Lisad > Lisa 1. 2. tÃ¼Ã¼pi diabeedi ravi algoritm\n",
      "*(PDF-tekstis esitatud algoritm on vooskeemina; siin on sÃ¤ilitatud tekstilised elemendid samas jÃ¤rjekorras.)*  \n",
      "- 2. tÃ¼Ã¼pi diabeet ja vÃ¤hemalt Ã¼ks jÃ¤rgmistest:\n",
      "- intensiivses eluviisisekkumise programmis mitte osalemine vÃµi\n",
      "- HbA1c â‰¥ 7,5% (58 mmol/mol) vÃµi\n",
      "- pÃ¼siva proteinuuriaga (>300 mg/g vÃµi >30 mg/mmol) kulgev krooniline neeruhaigus (KNH) vÃµi\n",
      "- langenud vÃ¤ljutusfraktsiooniga (<40%) krooniline sÃ¼damepuudulikkus  \n",
      "- HbA1c < 11%; 97 mmol/mol â€” **EI / JAH**\n",
      "- HbA1c < 9%; 75 mmol/mol â€” **EI / JAH**  \n",
      "- pÃ¼siva proteinuuriga (uACR >300 mg/g vÃµi >30 mg/mmol) kulgev KNH\n",
      "- langenud vÃ¤ljutusfraktsiooniga (< 40%) sÃ¼damepuudulikkus\n",
      "- **EI / JAH**\n",
      "- **ebasobiv**\n",
      "- Metformiin / SGLT2 inhibiitor  \n",
      "- pÃ¼siva proteinuuriga (uACR >300 mg/g vÃµi >30 mg/mmol) kulgev KNH\n",
      "- langenud vÃ¤ljutusfraktsiooniga (< 40%) sÃ¼damepuudulikkus\n",
      "- aterosklerootiline kardiovaskulaarhaigus\n",
      "- **EI**: metformiin, sulfonÃ¼Ã¼luurea\n",
      "- **ebasobiv**\n",
      "- **JAH**: SGLT2 inhibiitor  \n",
      "- pÃ¼siva proteinuuriga (uACR >300 mg/g vÃµi >30 mg/mmol) kulgev KNH\n",
      "- langenud vÃ¤ljutusfraktsiooniga (< 40%) sÃ¼damepuudulikkus\n",
      "- aterosklerootiline kardiovaskulaarhaigus\n",
      "- **EI / JAH**: metformiin, sulfonÃ¼Ã¼luurea, DPP4 inhibiitor, pioglitasoon, SGLT2 inhibiitor\n",
      "- **ebasobiv**\n",
      "- SGLT2 inhibiitor, GLP1 agonist\n",
      "- basaalinsuliin / GLP1 agonist\n",
      "- basaalinsuliini ja GLP1 agonisti kombinatsioon vÃµi\n",
      "- basaalinsuliini ja lÃ¼hitoimelise insuliini kombinatsioon vÃµi\n",
      "- seguinsuliin  \n",
      "Legend:\n",
      "- tugev soovitus ravimrÃ¼hma kasutamiseks\n",
      "- nÃµrk soovitus ravimrÃ¼hma kasutamise kaalumiseks\n",
      "- ebasobiv â€“ sisaldub juba raviskeemis, vastunÃ¤idustatud vÃµi esinevad pÃ¼sivad kÃµrvaltoimed  \n",
      "- III. intensiivistamine: vajadus sÃµltub ravi eesmÃ¤rkvÃ¤Ã¤rtusest\n",
      "- II. intensiivistamine: vajadus sÃµltub ravi eesmÃ¤rkvÃ¤Ã¤rtusest\n",
      "- I. intensiivistamine: vajadus sÃµltub ravi eesmÃ¤rkvÃ¤Ã¤rtusest\n",
      "- ravi alustamine\n",
      "  source: 2. tÃ¼Ã¼bi diabeedi diagnostika ja ravi\n",
      "  year: 2021\n",
      "  language: et\n",
      "  search_text (snippet): Lisad > Lisa 1. 2. tÃ¼Ã¼pi diabeedi ravi algoritm *(PDF-tekstis esitatud algoritm on vooskeemina; siin on sÃ¤ilitatud tekstilised elemendid samas jÃ¤rjekorras.)*   - 2. tÃ¼Ã¼pi diabeet ja vÃ¤hemalt Ã¼ks jÃ¤rgmistest: - intensiivses eluviisisekkumise programmis mitte osâ€¦\n",
      "\n",
      "[5] uuid=155f3506-e62f-463c-91f5-9bd5e0986c88\n",
      "  chunk_id: 4\n",
      "  search_text: Ravijuhendi kÃ¤sitlusala ja sihtrÃ¼hm\n",
      "Ravijuhendi eesmÃ¤rk on aidata kaasa 2. tÃ¼Ã¼pi diabeedi varajasele diagnoosimisele. Samuti 2. tÃ¼Ã¼pi diabeedi tÃ¼sistuste ennetamine ja/vÃµi edasilÃ¼kkamine, esmatasandil diabeedihaigete jÃ¤lgimise suutlikkuse parandamine, eriarstiabis tehtavate pÃµhjendamata visiitide hulga vÃ¤hendamine, 2. tÃ¼Ã¼pi diabeediga seotud vÃ¤lditavate hospitaliseerimiste vÃ¤hendamine ja diabeedipatsiendi liikumise Ã¼htlustumine erialaspetsialistide vahel.  \n",
      "Ravijuhend on mÃµeldud kasutamiseks perearstidele ja -Ãµdedele ning teistele tervishoiutÃ¶Ã¶tajatele, kes puutuvad kokku 2. tÃ¼Ã¼pi diabeeti pÃµdeva patsiendi raviga. Ravijuhend hÃµlmab prediabeediga inimesi ja 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiente alates 18. eluaastast.  \n",
      "Ravijuhend kÃ¤sitleb:\n",
      "- riskirÃ¼hma kuuluvate asÃ¼mptomaatiliste inimeste sÃµelumist,\n",
      "- 2. tÃ¼Ã¼pi diabeedi diagnoosimist,\n",
      "- diagnoosiga patsiendil ravi alustamist ja -intensiivistamist,\n",
      "- insuliinravi alustamist,\n",
      "- ravieesmÃ¤rke,\n",
      "- vere glÃ¼koosisisalduse enesekontrolli glÃ¼komeetriga,\n",
      "- 2. tÃ¼Ã¼pi diabeedi diagnoosiga patsiendi jÃ¤lgimist.  \n",
      "Ravijuhendis ei kÃ¤sitleta:\n",
      "- 1. tÃ¼Ã¼pi diabeet;\n",
      "- diabeet lastel ja noortel;\n",
      "- rasedusaegne diabeet;\n",
      "- teised spetsiifilised diabeeditÃ¼Ã¼bid (pankreatogeenne diabeet, MODY jt);\n",
      "- diabeedi tÃ¼sistused ja nende ravi;\n",
      "- diabeedi mittefarmakoloogiline ravi.  \n",
      "Ravijuhendi soovitused lÃ¤htuvad tÃµenduspÃµhiste uuringute tulemustest ja kliinilisest praktikast. Ravijuhend ei asenda tervishoiutÃ¶Ã¶taja individuaalset vastutust teha Ãµigeid raviotsuseid konkreetsest patsiendist lÃ¤htudes. KÃµik soovitused ei pruugi kÃµigile patsientidele sobida.  \n",
      "---\n",
      "  source: 2. tÃ¼Ã¼bi diabeedi diagnostika ja ravi\n",
      "  year: 2021\n",
      "  language: et\n",
      "  search_text (snippet): Ravijuhendi kÃ¤sitlusala ja sihtrÃ¼hm Ravijuhendi eesmÃ¤rk on aidata kaasa 2. tÃ¼Ã¼pi diabeedi varajasele diagnoosimisele. Samuti 2. tÃ¼Ã¼pi diabeedi tÃ¼sistuste ennetamine ja/vÃµi edasilÃ¼kkamine, esmatasandil diabeedihaigete jÃ¤lgimise suutlikkuse parandamine, eriarstiâ€¦\n"
     ]
    }
   ],
   "source": [
    "# Lets test different query setups\n",
    "# Start with help function\n",
    "def show_results(title, resp, fields=(\"chunk_id\",\"search_text\",\"source\",\"year\",\"language\"), max_text_chars=260):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(title)\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    if not resp.objects:\n",
    "        print(\"No results.\")\n",
    "        return\n",
    "\n",
    "    for i, obj in enumerate(resp.objects, start=1):\n",
    "        props = obj.properties or {}\n",
    "        print(f\"\\n[{i}] uuid={obj.uuid}\")\n",
    "        for f in fields:\n",
    "            print(f\"  {f}: {props.get(f)}\")\n",
    "        text = props.get(\"search_text\") or \"\"\n",
    "        text = text.replace(\"\\n\", \" \").strip()\n",
    "        if len(text) > max_text_chars:\n",
    "            text = text[:max_text_chars] + \"â€¦\"\n",
    "        print(f\"  search_text (snippet): {text}\")\n",
    "\n",
    "with weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    ") as client:\n",
    "    col = client.collections.use(\"Guideline\")\n",
    "\n",
    "    # Put your test query here:\n",
    "    q = \"2. tÃ¼Ã¼bi diabeedi ravi metformiin\"\n",
    "\n",
    "    # You can run any of the strategies below inside this context.\n",
    "    resp = col.query.near_text(\n",
    "    query=q,\n",
    "    limit=5,\n",
    "    return_properties=[\"chunk_id\",\"search_text\",\"source\",\"year\",\"language\"]\n",
    ")\n",
    "show_results(\"A) near_text (semantic)\", resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a764dddb-e312-4e4b-9585-0befc1b93974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import weaviate\n",
    "from weaviate.auth import Auth\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"WEAVIATE_URL\")\n",
    "assert os.getenv(\"WEAVIATE_API_KEY\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "COLLECTION_NAME = \"Guideline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3802e6b-89ca-4f26-8bd1-ccf9e9ea8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_strategies(\n",
    "    query: str,\n",
    "    k: int = 5,\n",
    "    hybrid_alphas=(0.2, 0.5, 0.8),\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    with weaviate.connect_to_weaviate_cloud(\n",
    "        cluster_url=WEAVIATE_URL,\n",
    "        auth_credentials=Auth.api_key(WEAVIATE_API_KEY),\n",
    "    ) as client:\n",
    "        col = client.collections.use(COLLECTION_NAME)\n",
    "\n",
    "        props = [\"search_text\", \"breadcrumbs\", \"chunk_id\", \"source\", \"year\"]\n",
    "\n",
    "        # BM25\n",
    "        resp = col.query.bm25(query=query, limit=k, return_properties=props)\n",
    "        rows.append((\"bm25\", None, resp.objects))\n",
    "\n",
    "        # near_text\n",
    "        resp = col.query.near_text(query=query, limit=k, return_properties=props)\n",
    "        rows.append((\"near_text\", None, resp.objects))\n",
    "\n",
    "        # hybrid sweep\n",
    "        for a in hybrid_alphas:\n",
    "            resp = col.query.hybrid(query=query, alpha=a, limit=k, return_properties=props)\n",
    "            rows.append((\"hybrid\", a, resp.objects))\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1f6e15f-812a-4de0-8268-42f5cbd35055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaumov/Documents/code/weekend_projects/learning_splitting/venv/lib/python3.14/site-packages/langchain_core/runnables/utils.py:756: DeprecationWarning: 'asyncio.iscoroutinefunction' is deprecated and slated for removal in Python 3.16; use inspect.iscoroutinefunction() instead\n",
      "  return asyncio.iscoroutinefunction(func) or (\n",
      "/Users/nikitaumov/Documents/code/weekend_projects/learning_splitting/venv/lib/python3.14/site-packages/langchain_core/runnables/utils.py:758: DeprecationWarning: 'asyncio.iscoroutinefunction' is deprecated and slated for removal in Python 3.16; use inspect.iscoroutinefunction() instead\n",
      "  and asyncio.iscoroutinefunction(func.__call__)\n"
     ]
    }
   ],
   "source": [
    "class RetrievalJudgeResult(BaseModel):\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "\n",
    "    retrieval_relevance: int = Field(ge=1, le=5)\n",
    "    coverage: int = Field(ge=1, le=5)\n",
    "    groundedness: int = Field(ge=1, le=5)\n",
    "    noise: int = Field(ge=1, le=5, description=\"5 = very noisy, 1 = very clean\")\n",
    "    overall: int = Field(ge=1, le=5)\n",
    "\n",
    "    verdict: str\n",
    "    issues: list[str]\n",
    "    notes: str\n",
    "\n",
    "\n",
    "judge_llm = ChatOpenAI(\n",
    "    model=\"gpt-5.2\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "judge_structured = judge_llm.with_structured_output(\n",
    "    RetrievalJudgeResult,\n",
    "    method=\"json_schema\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "JUDGE_PROMPT = \"\"\"\n",
    "Developer: Evaluate SEARCH RESULTS for a given QUERY, focusing on the relevance and quality of retrieved contentâ€”not answering the query itself.\n",
    "\n",
    "Inputs:\n",
    "- QUERY: Search query string.\n",
    "- RETRIEVED CHUNKS: List of retrieved content strings.\n",
    "\n",
    "Checklist:\n",
    "- Review QUERY and all RETRIEVED CHUNKS.\n",
    "- Assess relevance of each chunk to the query.\n",
    "- Determine if chunks collectively address the query's scope.\n",
    "- Check for substantive (not superficial) topic coverage.\n",
    "- Identify any irrelevant or noisy content.\n",
    "- Assign scores per evaluation dimension.\n",
    "- Synthesize results and assign a verdict.\n",
    "\n",
    "Scoring (1â€“5 integers):\n",
    "- retrieval_relevance: Do chunks address the query?\n",
    "- coverage: Do chunks cover the full query intent?\n",
    "- groundedness: Are contents deeply connected to the true topic?\n",
    "- noise: Amount of unrelated/misleading content (5 = very noisy, 1 = almost none).\n",
    "- overall: Holistic retrieval quality.\n",
    "\n",
    "Verdict rules:\n",
    "- good: overall â‰¥ 4 AND retrieval_relevance â‰¥ 4 AND noise â‰¤ 2\n",
    "- bad: overall â‰¤ 2 OR retrieval_relevance â‰¤ 2\n",
    "- borderline: otherwise\n",
    "\n",
    "Before finalizing, check that scores and verdict match these rules; adjust if needed.\n",
    "\n",
    "Output ONLY this JSON structure, in order:\n",
    "- retrieval_relevance\n",
    "- coverage\n",
    "- groundedness\n",
    "- noise\n",
    "- overall\n",
    "- verdict\n",
    "\n",
    "Example:\n",
    "{\n",
    "  \"retrieval_relevance\": 4,\n",
    "  \"coverage\": 5,\n",
    "  \"groundedness\": 4,\n",
    "  \"noise\": 1,\n",
    "  \"overall\": 4,\n",
    "  \"verdict\": \"good\"\n",
    "}\n",
    "\n",
    "If QUERY or RETRIEVED CHUNKS is missing or invalid, return ONLY:\n",
    "{\n",
    "  \"error\": \"Description of the problem.\"\n",
    "}\n",
    "\n",
    "Strictly follow the schema; no extra fields or output.\n",
    "\"\"\"\n",
    "\n",
    "def judge_retrieval(query: str, chunks: list[str]) -> dict:\n",
    "    context = \"\\n\\n\".join(f\"[{i+1}] {c}\" for i, c in enumerate(chunks))\n",
    "\n",
    "    msg = f\"\"\"\n",
    "QUERY:\n",
    "{query}\n",
    "\n",
    "RETRIEVED CHUNKS:\n",
    "{context}\n",
    "\"\"\"\n",
    "    res = judge_structured.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": JUDGE_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": msg},\n",
    "        ]\n",
    "    )\n",
    "    return res.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "790626bb-7984-4975-9ac6-fb97cfc7ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Millal tuleb 2. tÃ¼Ã¼pi diabeediga patsient suunata endokrinoloogi vastuvÃµtule?\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "160c300a-8be5-445f-b36f-cec60887b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for q in queries:\n",
    "    all_results = retrieve_all_strategies(q, k=5)\n",
    "\n",
    "    for strategy, alpha, objs in all_results:\n",
    "        chunks = []\n",
    "        for obj in objs:\n",
    "            p = obj.properties or {}\n",
    "            chunks.append(p.get(\"search_text\") or \"\")\n",
    "\n",
    "        judgment = judge_retrieval(q, chunks)\n",
    "\n",
    "        for rank, obj in enumerate(objs, start=1):\n",
    "            p = obj.properties or {}\n",
    "            rows.append({\n",
    "                \"query\": q,\n",
    "                \"strategy\": strategy,\n",
    "                \"alpha\": alpha,\n",
    "                \"rank\": rank,\n",
    "                \"chunk_id\": p.get(\"chunk_id\"),\n",
    "                \"breadcrumbs\": p.get(\"breadcrumbs\"),\n",
    "                \"search_text\": p.get(\"search_text\"),\n",
    "                **judgment,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee7ab96d-ebe5-4fc9-a2c0-6558c50626fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df = df.sort_values(\n",
    "    [\"query\", \"strategy\", \"alpha\", \"rank\"]\n",
    ")\n",
    "\n",
    "df[\n",
    "    [\n",
    "        \"query\",\n",
    "        \"strategy\",\n",
    "        \"alpha\",\n",
    "        \"rank\",\n",
    "        \"chunk_id\",\n",
    "        \"breadcrumbs\",\n",
    "        \"search_text\",\n",
    "    ]\n",
    "]\n",
    "df[\"alpha_label\"] = df.apply(\n",
    "    lambda r: (\n",
    "        f\"{r['alpha']}\"\n",
    "        if r[\"strategy\"] == \"hybrid\"\n",
    "        else \"N/A\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5f3f6d9-4322-479e-89d7-24c9aa2e6823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec9b26bbccd403f97e8376fd2aa2673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='â¬… Previous', style=ButtonStyle()), Button(description='Next â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Button, VBox, HBox, Output\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "# ===============================\n",
    "# SAFETY & PREP\n",
    "# ===============================\n",
    "required_cols = {\n",
    "    \"query\", \"strategy\", \"alpha_label\", \"rank\",\n",
    "    \"chunk_id\", \"breadcrumbs\", \"search_text\"\n",
    "}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"df is missing required columns: {missing}\")\n",
    "\n",
    "# Ensure relevance column exists\n",
    "if \"human_relevance\" not in df.columns:\n",
    "    df[\"human_relevance\"] = pd.NA\n",
    "\n",
    "# Normalize relevance column\n",
    "df[\"human_relevance\"] = pd.to_numeric(\n",
    "    df[\"human_relevance\"], errors=\"coerce\"\n",
    ").fillna(-1).astype(int)\n",
    "\n",
    "# Reset index for navigation\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# ===============================\n",
    "# STATE\n",
    "# ===============================\n",
    "current_idx = 0\n",
    "out = Output()\n",
    "\n",
    "# ===============================\n",
    "# UI ELEMENTS\n",
    "# ===============================\n",
    "prev_btn = Button(description=\"â¬… Previous\")\n",
    "next_btn = Button(description=\"Next âž¡\")\n",
    "save_csv_btn = Button(description=\"ðŸ’¾ Save to CSV\", button_style=\"warning\")\n",
    "\n",
    "btn_0 = Button(description=\"0\", button_style=\"danger\", tooltip=\"Irrelevant\")\n",
    "btn_1 = Button(description=\"1\", tooltip=\"Weakly relevant\")\n",
    "btn_2 = Button(description=\"2\", button_style=\"info\", tooltip=\"Relevant\")\n",
    "btn_3 = Button(description=\"3\", button_style=\"success\", tooltip=\"Highly relevant\")\n",
    "\n",
    "rating_buttons = HBox([btn_0, btn_1, btn_2, btn_3])\n",
    "\n",
    "# ===============================\n",
    "# RENDER FUNCTION (HTML, NOT MARKDOWN)\n",
    "# ===============================\n",
    "def render_row(idx):\n",
    "    row = df.loc[idx]\n",
    "\n",
    "    # Escape text for HTML safety\n",
    "    query = html.escape(str(row[\"query\"]))\n",
    "    search_text = html.escape(str(row[\"search_text\"]))\n",
    "    breadcrumbs = html.escape(str(row[\"breadcrumbs\"]))\n",
    "    rating = row[\"human_relevance\"]\n",
    "\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"font-family: monospace; line-height: 1.5;\">\n",
    "            <h2>ðŸ”Ž Retrieval Review ({idx+1} / {len(df)})</h2>\n",
    "\n",
    "            <b>Query:</b>\n",
    "            <div style=\"margin-bottom: 10px;\">{query}</div>\n",
    "\n",
    "            <b>Strategy:</b> {row['strategy']}<br>\n",
    "            <b>Alpha:</b> {row['alpha_label']}<br>\n",
    "            <b>Rank:</b> {row['rank']}<br>\n",
    "            <b>Chunk ID:</b> {row['chunk_id']}<br>\n",
    "            <b>Breadcrumbs:</b> {breadcrumbs}\n",
    "\n",
    "            <hr>\n",
    "\n",
    "            <h3>search_text</h3>\n",
    "            <pre style=\"\n",
    "                white-space: pre-wrap;\n",
    "                background: #f8f8f8;\n",
    "                border: 1px solid #ddd;\n",
    "                padding: 12px;\n",
    "                max-height: 400px;\n",
    "                overflow-y: auto;\n",
    "            \">{search_text}</pre>\n",
    "\n",
    "            <hr>\n",
    "\n",
    "            <b>Current rating:</b> {rating if rating >= 0 else \"not rated\"}<br>\n",
    "            <small>0 = irrelevant Â· 1 = weak Â· 2 = relevant Â· 3 = highly relevant</small>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "# ===============================\n",
    "# HANDLERS\n",
    "# ===============================\n",
    "def set_rating(value):\n",
    "    global current_idx\n",
    "    df.loc[current_idx, \"human_relevance\"] = value\n",
    "    render_row(current_idx)\n",
    "\n",
    "def prev_row(_):\n",
    "    global current_idx\n",
    "    if current_idx > 0:\n",
    "        current_idx -= 1\n",
    "        render_row(current_idx)\n",
    "\n",
    "def next_row(_):\n",
    "    global current_idx\n",
    "    if current_idx < len(df) - 1:\n",
    "        current_idx += 1\n",
    "        render_row(current_idx)\n",
    "\n",
    "def save_csv(_):\n",
    "    df.to_csv(\"manual_retrieval_review.csv\", index=False)\n",
    "    with out:\n",
    "        display(HTML(\"<b>ðŸ’¾ Saved to manual_retrieval_review.csv</b>\"))\n",
    "\n",
    "# Button bindings\n",
    "btn_0.on_click(lambda _: set_rating(0))\n",
    "btn_1.on_click(lambda _: set_rating(1))\n",
    "btn_2.on_click(lambda _: set_rating(2))\n",
    "btn_3.on_click(lambda _: set_rating(3))\n",
    "\n",
    "prev_btn.on_click(prev_row)\n",
    "next_btn.on_click(next_row)\n",
    "save_csv_btn.on_click(save_csv)\n",
    "\n",
    "# ===============================\n",
    "# DISPLAY\n",
    "# ===============================\n",
    "controls = HBox([prev_btn, next_btn, rating_buttons, save_csv_btn])\n",
    "display(VBox([controls, out]))\n",
    "\n",
    "render_row(current_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0fcec1ec-543b-4e51-a889-7729ee184d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>alpha_label</th>\n",
       "      <th>overall_mean</th>\n",
       "      <th>relevance_mean</th>\n",
       "      <th>coverage_mean</th>\n",
       "      <th>groundedness_mean</th>\n",
       "      <th>noise_mean</th>\n",
       "      <th>good_rate</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>near_text</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    strategy alpha_label  overall_mean  relevance_mean  coverage_mean  \\\n",
       "2     hybrid         0.5           5.0             5.0            4.0   \n",
       "3     hybrid         0.8           5.0             5.0            4.0   \n",
       "4  near_text         N/A           5.0             5.0            5.0   \n",
       "0       bm25         N/A           4.0             5.0            4.0   \n",
       "1     hybrid         0.2           4.0             5.0            4.0   \n",
       "\n",
       "   groundedness_mean  noise_mean  good_rate  n  \n",
       "2                5.0         1.0        1.0  5  \n",
       "3                5.0         1.0        1.0  5  \n",
       "4                5.0         1.0        1.0  5  \n",
       "0                5.0         2.0        1.0  5  \n",
       "1                5.0         2.0        1.0  5  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "summary = (\n",
    "    df.groupby([\"strategy\", \"alpha_label\"])\n",
    "    .agg(\n",
    "        overall_mean=(\"overall\", \"mean\"),\n",
    "        relevance_mean=(\"retrieval_relevance\", \"mean\"),\n",
    "        coverage_mean=(\"coverage\", \"mean\"),\n",
    "        groundedness_mean=(\"groundedness\", \"mean\"),\n",
    "        noise_mean=(\"noise\", \"mean\"),\n",
    "        good_rate=(\"verdict\", lambda s: (s == \"good\").mean()),\n",
    "        n=(\"overall\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"overall_mean\", ascending=False)\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152695e-4bce-4fd7-8357-dc346394cc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
